{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f3d0464a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 1, 1, 0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def AND_gate(x1, x2):\n",
    "  w1 = 0.5\n",
    "  w2 = 0.5\n",
    "  b = -0.7\n",
    "  result = x1*w1 + x2*w2 + b\n",
    "  if result <= 0:\n",
    "    return 0\n",
    "  else:\n",
    "    return 1\n",
    "\n",
    "def NAND_gate(x1, x2):\n",
    "    w1=-0.5\n",
    "    w2=-0.5\n",
    "    b=0.7\n",
    "    result = x1*w1 + x2*w2 + b\n",
    "    if result <= 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "    \n",
    "#  XOR 게이트 구현\n",
    "def XOR_gate(x1, x2):\n",
    "    w1=0.6\n",
    "    w2=0.6\n",
    "    b=-0.5\n",
    "    result = x1*w1 + x2*w2 + b\n",
    "    if result <= 0:\n",
    "      return AND_gate(x1, x2)  # 층을 하나 더 추가함으로 XOR 게이트를 구현 가능\n",
    "    else:\n",
    "      return NAND_gate(x1, x2)\n",
    "\n",
    "# 두개의 입력값이 서로 다른 값을 갖고 있을 때만 출력값이 1이 되고 나머진 0이 됨\n",
    "XOR_gate(0, 0), XOR_gate(0, 1), XOR_gate(1, 0), XOR_gate(1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "08e59e0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.7319304943084717\n",
      "100 0.693137526512146\n",
      "200 0.6931369304656982\n",
      "300 0.6931360960006714\n",
      "400 0.6931353807449341\n",
      "500 0.6931347250938416\n",
      "600 0.6931338310241699\n",
      "700 0.6931329965591431\n",
      "800 0.6931321620941162\n",
      "900 0.6931310892105103\n",
      "1000 0.6931300759315491\n"
     ]
    }
   ],
   "source": [
    "# XOR 게이트 구현(PyTorch)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# for reproducibility\n",
    "torch.manual_seed(1)\n",
    "\n",
    "# XOR 문제를 풀기 위한 입력과 출력 정의\n",
    "X = torch.FloatTensor([[0, 0], [0, 1], [1, 0], [1, 1]]).to(device)\n",
    "Y = torch.FloatTensor([[0], [1], [1], [0]]).to(device)\n",
    "\n",
    "# 다층 퍼셉트론 설계. 입력층, 은닉층1, 은닉층2, 은닉층3, 출력층을 가지는 인공신경망\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(2, 10, bias=True), # input_layer = 2, hidden_layer1 = 10\n",
    "    nn.Sigmoid(),\n",
    "    nn.Linear(10, 10, bias=True), # hidden_layer1 = 10, hidden_layer2 = 10\n",
    "    nn.Sigmoid(),\n",
    "    nn.Linear(10, 10, bias=True), # hidden_layer2 = 10, hidden_layer3 = 10\n",
    "    nn.Sigmoid(),\n",
    "    nn.Linear(10, 1, bias=True), # hidden_layer3 = 10, output_layer = 1\n",
    "    nn.Sigmoid()\n",
    ").to(device)\n",
    "\n",
    "# 비용 함수와 옵티마이저 선언\n",
    "criterion = torch.nn.BCELoss().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1)\n",
    "\n",
    "# 훈련 수행. 각 에포크마다 역전파 수행\n",
    "for epoch in range(1001):\n",
    "    optimizer.zero_grad() # backward()를 호출하고 나면 각 파라미터들의 .grad 값에 변화도가 저장이 된다. 저장된 값이 다음 루프의 업데이트에도 간섭하지 않도록 .grad 값들을 0으로 초기화 시켜준다.\n",
    "    # **zero_grad() 인자로 넘겨주는 set_to_none=False는 True로 넘기면 메모리 사용량이 적어져서 퍼포먼스가 소폭 향상 되지만, manual하게 .grad 값에 접근해서 수정을 할 때 다르게 작동해서 쓰이지 않는다. \n",
    "    \n",
    "    # forward 연산\n",
    "    hypothesis = model(X)\n",
    "\n",
    "    # 비용 함수\n",
    "    cost = criterion(hypothesis, Y)\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # 100의 배수에 해당되는 에포크마다 비용을 출력\n",
    "    if epoch % 100 == 0:\n",
    "        print(epoch, cost.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "020db09a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.6931300759315491\n",
      "100 0.6931289434432983\n",
      "200 0.6931277513504028\n",
      "300 0.6931264400482178\n",
      "400 0.6931250691413879\n",
      "500 0.6931235790252686\n",
      "600 0.6931218504905701\n",
      "700 0.6931201219558716\n",
      "800 0.6931182146072388\n",
      "900 0.6931160688400269\n",
      "1000 0.6931138038635254\n",
      "1100 0.6931111812591553\n",
      "1200 0.693108320236206\n",
      "1300 0.6931052207946777\n",
      "1400 0.6931016445159912\n",
      "1500 0.6930976510047913\n",
      "1600 0.6930931806564331\n",
      "1700 0.6930881142616272\n",
      "1800 0.693082332611084\n",
      "1900 0.6930756568908691\n",
      "2000 0.6930679678916931\n",
      "2100 0.6930590867996216\n",
      "2200 0.6930485963821411\n",
      "2300 0.6930360794067383\n",
      "2400 0.6930210590362549\n",
      "2500 0.6930028796195984\n",
      "2600 0.6929803490638733\n",
      "2700 0.6929522156715393\n",
      "2800 0.6929161548614502\n",
      "2900 0.6928691267967224\n",
      "3000 0.6928060054779053\n",
      "3100 0.6927184462547302\n",
      "3200 0.6925923228263855\n",
      "3300 0.6924009323120117\n",
      "3400 0.6920909881591797\n",
      "3500 0.6915416121482849\n",
      "3600 0.6904304623603821\n",
      "3700 0.6876454949378967\n",
      "3800 0.6771503686904907\n",
      "3900 0.59931880235672\n",
      "4000 0.4278465509414673\n",
      "4100 0.02223077416419983\n",
      "4200 0.007571122609078884\n",
      "4300 0.0042859651148319244\n",
      "4400 0.0029194862581789494\n",
      "4500 0.0021874327212572098\n",
      "4600 0.0017365964595228434\n",
      "4700 0.0014331906568259\n",
      "4800 0.0012161426711827517\n",
      "4900 0.0010536944027990103\n",
      "5000 0.0009278899524360895\n",
      "5100 0.0008277681772597134\n",
      "5200 0.0007462674984708428\n",
      "5300 0.0006787903839722276\n",
      "5400 0.0006220237701199949\n",
      "5500 0.0005736398161388934\n",
      "5600 0.000531997240614146\n",
      "5700 0.0004957086639478803\n",
      "5800 0.00046386412577703595\n",
      "5900 0.00043574755545705557\n",
      "6000 0.0004107027780264616\n",
      "6100 0.00038822260103188455\n",
      "6200 0.00036800879752263427\n",
      "6300 0.00034974818117916584\n",
      "6400 0.0003331275365781039\n",
      "6500 0.00031798292184248567\n",
      "6600 0.0003040607844013721\n",
      "6700 0.00029128658934496343\n",
      "6800 0.0002794963656924665\n",
      "6900 0.0002685856306925416\n",
      "7000 0.0002584650064818561\n",
      "7100 0.0002490748302079737\n",
      "7200 0.0002402958634775132\n",
      "7300 0.00023206844343803823\n",
      "7400 0.00022440744214691222\n",
      "7500 0.00021719365031458437\n",
      "7600 0.00021042703883722425\n",
      "7700 0.00020403308735694736\n",
      "7800 0.00019805648480542004\n",
      "7900 0.00019234820501878858\n",
      "8000 0.0001869827538030222\n",
      "8100 0.00018187068053521216\n",
      "8200 0.00017702691548038274\n",
      "8300 0.00017245144408661872\n",
      "8400 0.0001680697314441204\n",
      "8500 0.0001639265101402998\n",
      "8600 0.0001599472452653572\n",
      "8700 0.0001561617391416803\n",
      "8800 0.0001525401894468814\n",
      "8900 0.00014909748279023916\n",
      "9000 0.00014577401452697814\n",
      "9100 0.00014264430501498282\n",
      "9200 0.0001395891304127872\n",
      "9300 0.0001366829965263605\n",
      "9400 0.00013386629871092737\n",
      "9500 0.000131168810185045\n",
      "9600 0.0001285905746044591\n",
      "9700 0.00012608684482984245\n",
      "9800 0.00012368745228741318\n",
      "9900 0.00012137748854001984\n",
      "10000 0.0001191271367133595\n"
     ]
    }
   ],
   "source": [
    "# 10001\n",
    "for epoch in range(10001):\n",
    "    optimizer.zero_grad()\n",
    "    hypothesis = model(X)\n",
    "    cost = criterion(hypothesis, Y)\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    if epoch % 100 == 0:\n",
    "        print(epoch, cost.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0a97d216",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델의 출력값(Hypothesis):  [[9.6978256e-05]\n",
      " [9.9989307e-01]\n",
      " [9.9986112e-01]\n",
      " [1.3367381e-04]]\n",
      "모델의 예측값(Predicted):  [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "실제값(Y):  [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "정확도(Accuracy):  1.0\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    hypothesis = model(X)\n",
    "    predicted = (hypothesis > 0.5).float()\n",
    "    accuracy = (predicted == Y).float().mean()\n",
    "    print('모델의 출력값(Hypothesis): ', hypothesis.detach().cpu().numpy())\n",
    "    print('모델의 예측값(Predicted): ', predicted.detach().cpu().numpy())\n",
    "    print('실제값(Y): ', Y.cpu().numpy())\n",
    "    print('정확도(Accuracy): ', accuracy.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940fa9df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "model",
   "language": "python",
   "name": "model"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
